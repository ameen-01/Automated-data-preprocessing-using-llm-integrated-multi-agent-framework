# ğŸ§  AUTOMATED DATA PREPROCESSING USING LLM INTEGRATED MULTI AGENT FARMEWORK
##  Project Description 

#### This project implements an Agentic AIâ€“powered data cleaning system that automatically analyzes, plans, and cleans raw datasets using a coordinated set of intelligent agents. Instead of static rule-based preprocessing, this system uses a Controller Agent that dynamically selects appropriate cleaning steps based on dataset characteristicsâ€”making the entire process adaptive, explainable, and efficient.

#### The system is integrated into a Streamlit UI, enabling users to upload messy CSV files and receive a structured, cleaned output along with a detailed log of applied transformations.
### This project is built for:
- ML engineers
- Data scientists
- Researchers
- Students
#### Or Anyone who needs clean, standardized data quickly
#### The system completely offline after installing Ollama, or else it requires an API integration like openAI through API keys to run online.

## âœ¨ Key Features
### âœ”ï¸ Agentic AI Pipeline
#### A Controller Agent plans the cleaning steps based on dataset summary.
### âœ”ï¸ Specialized Cleaning Agents
- Missing Value Agent
- Outlier Correction Agent
- Type Correction Agent
- Duplicate Removal Agent
- Semantic Normalizer Agent (LLM-powered)
### âœ”ï¸ Local LLM Integration (Ollama)

### âœ”ï¸ Full Explainability Log
#### Every preprocessing step is recorded with:
- step name
- reason
- shape before
- shape after
### âœ”ï¸ Sankey Diagram Visualization
#### Shows the pipeline flow clearly.
### âœ”ï¸ Streamlit UI
#### Upload, preprocess, view logs, download output CSV.
